{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4_0c_Evx_xrS",
    "outputId": "91d5b7dd-aa00-48f8-980c-6328de775f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "'''ResNet in PyTorch.\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, embedding_size=12):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, embedding_size)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1,3,32,32))\n",
    "    print(y.size())\n",
    "  \n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Mir2nB7MAVa5"
   },
   "outputs": [],
   "source": [
    "embed1=ResNet18()\n",
    "embed2= ResNet18()\n",
    "embed3= ResNet18()\n",
    "embed4= ResNet18()\n",
    "embed5= ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "45BtIIwWV0U0"
   },
   "outputs": [],
   "source": [
    "class ProxyNCA(torch.nn.Module):\n",
    "    def __init__(self, batch_num, sz_embed):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.proxies = torch.nn.Parameter(torch.randn(batch_num, sz_embed) / 8)\n",
    "#         self.proxies= torch.nn.Parameter(torch.FloatTensor([[4,5,6],[4,5,6]])) \n",
    "# answer of this is 0.0025\n",
    "#         print(self.proxies.shape)\n",
    "\n",
    "    def pairwise_distance(self,a,b):\n",
    "\n",
    "      return torch.sub(a,b).pow(2).to(device)\n",
    "    \n",
    "    def proxyNCAloss(self,X,P):\n",
    "\t\t\n",
    "#       pdist = nn.PairwiseDistance(p=2, keepdim=True)\n",
    "\n",
    "      nume_exp=self.pairwise_distance(X,P).to(device)\n",
    "\n",
    "      vect_denom= self.pairwise_distance_self(X).to(device)\n",
    "      denom= (torch.exp(-1*vect_denom)).to(device).sum(-1).to(device)\n",
    "      \n",
    "      nume_exp=torch.exp(-1*nume_exp).to(device)\n",
    "      \n",
    "      \n",
    "      proxy_nca_loss= (nume_exp.to(device)/denom.to(device)).to(device)\n",
    "\n",
    "      return proxy_nca_loss.sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def pairwise_distance_self(self,X):\n",
    "\n",
    "        final_tensor=X\n",
    "        final_tensor.to(device)\n",
    "        processed=torch.zeros([X.size()[0],X.size()[1]]).to(device)\n",
    "        for i in range(0,X.size()[1]):\n",
    "            for j in range(0,X.size()[1]):\n",
    "                if(i==j):\n",
    "                    continue\n",
    "                processed[0,i]=torch.add(torch.sub(final_tensor[0,i],final_tensor[0,j]).pow(2),processed[0,i])\n",
    "        return  processed\n",
    "\n",
    "     \t\n",
    "\n",
    "\n",
    "    def forwardold(self, X):\n",
    "\n",
    "      P = self.proxies.double()\n",
    "      P = 3 * F.normalize(P, p = 2, dim = -1)\n",
    "#       X = 3 * F.normalize(X, p = 2, dim = -1)\n",
    "\n",
    "      pdist = nn.PairwiseDistance(p=2, keepdim=True)\n",
    "\n",
    "      nume_exp=self.pairwise_distance(X,P)\n",
    "\n",
    "      vect_denom= self.pairwise_distance_self(X)\n",
    "      denom= (torch.exp(-1*vect_denom)).sum()\n",
    "\n",
    "#       proxy_nca_loss=-1* torch.log( (torch.exp(-1*nume_exp)/denom).sum())\n",
    "      proxy_nca_loss= (torch.exp(-1*nume_exp)/denom).sum()\n",
    "\n",
    "  \n",
    "      return proxy_nca_loss\n",
    "  \n",
    "    def forward(self, X):\n",
    "      P = self.proxies\n",
    "      P = 3 * F.normalize(P, p = 2, dim = -1)\n",
    "\n",
    "      X = 3 * F.normalize(X, p = 2, dim = -1)\n",
    "\n",
    "      batchwise_lose = torch.zeros_like(X)\n",
    "\n",
    "\n",
    "      if(X.size()[0]==1):\n",
    "        return self.forwardold(X)\n",
    "      \n",
    "      for i in range(0,X.size()[0]):\n",
    "#         >>> a[0].resize(a[0].size()[0],1).t().shape\n",
    "\n",
    "#         print(batchwise_lose[i].size())\n",
    "#         print(X[i].resize(X[i].size()[0],1).t())\n",
    "        \n",
    "        batchwise_lose[i]=self.proxyNCAloss(X[i].resize(X[i].size()[0],1).t(), \n",
    "                                            P[i].resize(P[i].size()[0],1).t()).to(device)\n",
    "#      \n",
    "#       taking sum of all the losses within a batch and then taking mean of all \n",
    "#       the batches as a representative loss\n",
    "#       print(batchwise_lose)\n",
    "      return batchwise_lose.sum(-1).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# testing\n",
    "\n",
    "# criterion= ProxyNCA(2,3)\n",
    "\n",
    "\n",
    "# # print(criterion())\n",
    "# print(torch.FloatTensor([[1,2,3],[1,2,3]]).shape)\n",
    "\n",
    "# loss= criterion(torch.FloatTensor([[1,2,3],[1,2,3]]))\n",
    "# print(loss.item())\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ETqWxIT2CT-b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "\n",
    "    return x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CUNNSeveCVT8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Transformations\n",
    "RC   = transforms.RandomCrop(32, padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TPIL, RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform_no_aug):\n",
    "        \"\"\"\n",
    "        datasets: a list of get_class_i outputs, i.e. a list of list of images for selected classes\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the absolute index, returns which bin it falls in and which element of that bin it corresponds to.\n",
    "        \"\"\"\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hekMhrN0CaHD",
    "outputId": "cf76cc87-cd24-416e-8d0e-a5200f954e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "trainset  = CIFAR10(root='./data', train=True , download=True)#, transform = transform_with_aug)\n",
    "testset   = CIFAR10(root='./data', train=False, download=True)#, transform = transform_no_aug)\n",
    "\n",
    "# print(trainset.train_list)\n",
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# print(trainset.targets)\n",
    "\n",
    "x_train  = trainset.data\n",
    "x_test   = testset.data\n",
    "y_train  = trainset.targets\n",
    "y_test   = testset.targets\n",
    "# print(get_class_i(x_train, y_train, classDict['cat']))\n",
    "cat_dog_trainset = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['cat']), get_class_i(x_train, y_train, classDict['dog'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "plane_ship_trainset=\\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), get_class_i(x_train, y_train, classDict['ship'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "car_truck_trainset= \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['car']), get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "deer_horse_trainset= \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['deer']), get_class_i(x_train, y_train, classDict['horse'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "bird_frog_trainset= \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['bird']), get_class_i(x_train, y_train, classDict['frog'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "\n",
    "\n",
    "# One test set\n",
    "car_truck_testset  = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_test , y_test , classDict['car']), get_class_i(x_test , y_test , classDict['truck'])],\n",
    "        transform_no_aug\n",
    "    )\n",
    "\n",
    "# size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uEgQQNkZCalE"
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': False}\n",
    "\n",
    "# Create datasetLoaders from trainset and testset\n",
    "embed1_loader= DataLoader(cat_dog_trainset, batch_size=100, shuffle=True , **kwargs)\n",
    "embed2_loader= DataLoader(plane_ship_trainset, batch_size=100, shuffle=True , **kwargs)\n",
    "embed3_loader= DataLoader(car_truck_trainset, batch_size=100, shuffle=True , **kwargs)\n",
    "embed4_loader= DataLoader(deer_horse_trainset, batch_size=100, shuffle=True , **kwargs)\n",
    "embed5_loader= DataLoader(bird_frog_trainset, batch_size=100, shuffle=True , **kwargs)\n",
    "\n",
    "\n",
    "testsetLoader    = DataLoader(car_truck_testset , batch_size=64, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "YXRgEscOW5Tf",
    "outputId": "d73b1612-3020-49f4-e016-63ea57a86473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  10\n",
      "Loss 1:  13147.51171875\n",
      "Loss 2:  55.974002838134766\n",
      "Loss 3:  39.5790901184082\n",
      "Loss 4:  4134.5341796875\n",
      "Loss 5:  16709.517578125\n",
      "_________________________________________________________\n",
      "Iteration :  20\n",
      "Loss 1:  13087.8837890625\n",
      "Loss 2:  55.95524215698242\n",
      "Loss 3:  39.57583999633789\n",
      "Loss 4:  4134.1123046875\n",
      "Loss 5:  16704.390625\n",
      "_________________________________________________________\n",
      "Iteration :  30\n",
      "Loss 1:  13118.4794921875\n",
      "Loss 2:  55.97800064086914\n",
      "Loss 3:  39.5772705078125\n",
      "Loss 4:  4134.140625\n",
      "Loss 5:  16715.396484375\n",
      "_________________________________________________________\n",
      "Iteration :  40\n",
      "Loss 1:  13080.44140625\n",
      "Loss 2:  55.969242095947266\n",
      "Loss 3:  39.57606506347656\n",
      "Loss 4:  4134.564453125\n",
      "Loss 5:  16718.783203125\n",
      "_________________________________________________________\n",
      "Iteration :  50\n",
      "Loss 1:  13129.3974609375\n",
      "Loss 2:  55.96794891357422\n",
      "Loss 3:  39.57728576660156\n",
      "Loss 4:  4133.83935546875\n",
      "Loss 5:  16699.673828125\n",
      "_________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "# data,target=next(embed1_it)\n",
    "# print(data.shape)\n",
    "\n",
    "def set_status_train():\n",
    "#     embed1.double()\n",
    "#     embed2.double()\n",
    "#     embed3.double()\n",
    "#     embed4.double()\n",
    "#     embed5.double()\n",
    "    \n",
    "    embed1.train()\n",
    "    embed2.train()\n",
    "    embed3.train()\n",
    "    embed4.train()\n",
    "    embed5.train()\n",
    "\n",
    "\n",
    "\n",
    "criterion1 = ProxyNCA(100,12).to(device)\n",
    "criterion2 = ProxyNCA(100,12).to(device)\n",
    "criterion3 = ProxyNCA(100,12).to(device)\n",
    "criterion4 = ProxyNCA(100,12).to(device)\n",
    "criterion5 = ProxyNCA(100,12).to(device)\n",
    "\n",
    "optimizer1 = optim.SGD(embed1.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer2 = optim.SGD(embed2.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer3 = optim.SGD(embed3.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer4 = optim.SGD(embed4.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer5 = optim.SGD(embed5.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "  \n",
    "    embed1_it= iter(embed1_loader)\n",
    "    embed2_it= iter(embed2_loader)\n",
    "    embed3_it= iter(embed3_loader)\n",
    "    embed4_it= iter(embed4_loader)\n",
    "    embed5_it= iter(embed5_loader)\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    it=0\n",
    "    max_accuracy=0\n",
    "    final_loss=0\n",
    "    \n",
    "    set_status_train()\n",
    "\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(embed1_loader):\n",
    "      \n",
    "        try:\n",
    "            data1, target1 = next(embed1_it)\n",
    "            data2, target2 = next(embed2_it)\n",
    "            data3, target3 = next(embed3_it)\n",
    "            data4, target4 = next(embed4_it)\n",
    "            data5, target5 = next(embed5_it)\n",
    "        except StopIteration:\n",
    "            embed1_it= iter(embed1_loader)\n",
    "            embed2_it= iter(embed2_loader)\n",
    "            embed3_it= iter(embed3_loader)\n",
    "            embed4_it= iter(embed4_loader)\n",
    "            embed5_it= iter(embed5_loader)\n",
    "\n",
    "            data1, target1 = next(embed1_it)\n",
    "            data2, target2 = next(embed2_it)\n",
    "            data3, target3 = next(embed3_it)\n",
    "            data4, target4 = next(embed4_it)\n",
    "            data5, target5 = next(embed5_it)\n",
    "            \n",
    "        it=it+1\n",
    "        data1, target1 = data1.to(device), target1.to(device)\n",
    "        data2, target2 = data2.to(device), target2.to(device)\n",
    "        data3, target3 = data3.to(device), target3.to(device)\n",
    "        data4, target4 = data4.to(device), target4.to(device)\n",
    "        data5, target5 = data5.to(device), target5.to(device)\n",
    "        \n",
    "#          \n",
    "          \n",
    "        if(data1.size()[0]<10 or data2.size()[0]<10 or data3.size()[0]<10 or data4.size()[0]<10\n",
    "          or data5.size()[0]<10):\n",
    "          continue\n",
    "          \n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "        optimizer4.zero_grad()\n",
    "        optimizer5.zero_grad()\n",
    "        \n",
    "        embed1.to(device)\n",
    "        embed2.to(device)\n",
    "        embed3.cuda()\n",
    "        embed4.cuda()\n",
    "        embed5.cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         outputs = torch.cat([embed1(data1),embed2(data2),embed3(data3),embed4(data4),embed5(data5)],-1)\n",
    "#         print(outputs.size())\n",
    "        loss1=criterion1(embed1(data1)).to(device)\n",
    "        loss2=criterion2(embed2(data1)).to(device)\n",
    "        loss3=criterion3(embed3(data1))\n",
    "        loss4=criterion4(embed4(data1))\n",
    "        loss5=criterion5(embed5(data1))\n",
    "        \n",
    "\n",
    "        loss1.backward()\n",
    "        loss2.backward()\n",
    "        loss3.backward()\n",
    "        loss4.backward()\n",
    "        loss5.backward()\n",
    "        \n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        optimizer3.step()\n",
    "        optimizer4.step()\n",
    "        optimizer5.step()\n",
    "        \n",
    "        if(it%10==0):\n",
    "          print(\"Iteration : \", it)\n",
    "          print(\"Loss 1: \",loss1.item())\n",
    "          print(\"Loss 2: \",loss2.item())\n",
    "          print(\"Loss 3: \",loss3.item())\n",
    "          print(\"Loss 4: \",loss4.item())\n",
    "          print(\"Loss 5: \",loss5.item())\n",
    "          print(\"_________________________________________________________\")\n",
    "          \n",
    "          \n",
    "for epoch in range(2):          \n",
    "  train(epoch)\n",
    "# try:\n",
    "#             data, target = next(dataloader_iterator)\n",
    "#         except StopIteration:\n",
    "#             dataloader_iterator = iter(dataloader)\n",
    "#             data, target = next(dataloader_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "al6hj4IwKstM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ensemble Resnet With ProxyNCA Loss.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
